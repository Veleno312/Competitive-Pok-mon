  # -*- coding: utf-8 -*-
  """Análisis_Kaggle (el bueno).ipynb

  Automatically generated by Colab.

  Original file is located at
      https://colab.research.google.com/drive/1nxgxFFK1cOb73Qb3kVvUFM_ktY9ge6wc

  # Análisis de Pokémon competitivo

  Uno de los aspectos de Pokémon menos conocidos es el mundo competitivo. En esta parte del juego más conocido del mundo, jugadores entrenan sus Pokémon hasta su peak, y después combaten entre sí, para ver quién es el mejor.

  Un subconjunto de esta parte es la comunidad de Smogon quienes, de manera no oficial, ofrecen un servidor para jugar combates con Pokémon muy fáciles de crear y modificar, lo que permite usar más estrategias en menos tiempo. Además de esto, poseen un registro de todas las estrategias utilizadas, así como varios archivos donde guardan la información de cada Pokémon, sus movimientos, habilidades,...

  En este cuaderno, no solo trabajaremos con estos datos, sino también con los obtenidos de la página web Bulbapedia, para responder a la pregunta.

  ¿Se puede clasificar a los Pokémon de antemano, sabiendo solo los stats?

  ##Obtención de datos

  En estas primeras lineas buscamos obtener los datos referentes a los Pokémon, sus stats, movepools, habilidades, etc. Por lo que accedemos a ellos mediante las páginas de Smogon usando el paquete de urllib. Después almacenamos todos estos datos en un DataFrame del paquete pandas.
  """

from ast import Break
import warnings
import itertools
import urllib3
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from bs4 import BeautifulSoup
import pandas as pd
import json
import re
import numpy as np
import pandas as pd
import json
import re
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import numpy as np
from collections import defaultdict
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import urllib.request
import seaborn as sns
import matplotlib.pyplot as plt
import math
import numpy as np
import statistics as st
import math
from bs4 import BeautifulSoup
import pandas as pd
from sklearn import linear_model
from sklearn import feature_selection
from sklearn.metrics import mean_squared_error
from sklearn.utils import resample
import sklearn.ensemble as ens
import sklearn.tree as tree
from sklearn.model_selection import cross_val_score
import numpy as np
from sklearn.pipeline import make_pipeline
from sklearn import linear_model
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.utils import check_random_state
import numpy as np
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
import sklearn.ensemble as ens
valores_regresor=[]
class LazyDecoder(json.JSONDecoder):
    def decode(self, s, **kwargs):
        regex_replacements = [
            (re.compile(r'([^\\])\\([^\\])'), r'\1\\\\\2'),
            (re.compile(r',(\s*])'), r'\1'),
        ]
        for regex, replacement in regex_replacements:
            s = regex.sub(replacement, s)
        return super().decode(s, **kwargs)
gens=['xy','sm','ss']
df_final=pd.DataFrame(columns=gens)
for gen in gens:
    urllib3.disable_warnings()
    http = urllib3.PoolManager()
    website = 'https://www.smogon.com/dex/'+ gen +'/pokemon/'
    openwebsite = http.request('GET', website)
    links=openwebsite.data
    links=str(links)
    links=links.replace('href','')
    links=links.replace("b\'",'')
    links=links.replace('<html>','')
    links=links.split('pokemon')
    links=links[1]
    links=links.split('1v1')
    links=links[0]
    links=links[3:]
    links=links[:-22]
    links=links.split('},')
    for i in range(len(links)):
      if i<len(links)-1:
        links[i]=links[i]+'}'
      links[i]=json.loads(links[i],cls=LazyDecoder)
      if links[i]['oob'] is not None:
        links[i]['evos']=links[i]['oob']['evos']
        links[i]['alts']=links[i]['oob']['alts']
      else:
        links[i]['evos']=[]
        links[i]['alts']=[]
      del links[i]['oob']
    df=pd.DataFrame.from_dict(links[0],orient='index')
    df=df.transpose()
    for i in range(len(links)-1):
      df2=pd.DataFrame.from_dict(links[i+1],orient='index')
      df2=df2.transpose()
      df=pd.concat([df,df2],ignore_index=True)
    df['bst']=[sum(df[['hp','atk','def','spa','spd','spe']].values.tolist()[i]) for i in range(len(df))]
    df['offensive_prowess']=[max(df[['atk','spa']].values.tolist()[i])/df['bst'].values.tolist()[i] for i in range(len(df))]
    df['defensive_prowess']=[sum(df[['hp','def','spd']].values.tolist()[i])/df['bst'].values.tolist()[i] for i in range(len(df))]
    t=df['formats']
    s=[]
    for el in t:
      if el!=[]:
        s.append(el[0])
      else:
        s.append('None')
    df['formats']=s
    s=[]
    t=[]
    for x in df['evos']:
      if x==[]:
        t.append(0)
      else:
        t.append(1)
    df['Eviolite']=t
    df.head()

    for el in df['name']:
      if (el.find('Farfetch')!=-1 and el.find('Galar')==-1) or el.find('Oricorio-Pa')!=-1:
          string=el[-3:-1]
          break
    for i in range(len(df['name'])):
      el=df['name'][i]
      if el.find(string)!=-1:
        df.iloc[i,0]=el.replace(string,"'")
        el=el.replace(string,"'")
        print(el)

    """Aquí vemos los datos de un Pokémon en particular, Zygarde-10%. Este Pokémon nos enseña varias cosas, en particular la existencia de formas alternativas. Hay Pokémon que tienen diferentes formas, y formas que no aparecen en la tabla de usos. En las siguientes líneas de códigos eliminamos todos estos datos."""
    t=[]
    for i in range(len(df['name'])):
      if str(df['name'][i]).find('Necrozma-D')!=-1: #Modificamos estos nombres
        df['name'][i]=df['name'][i].replace(' ','-')
        print(df['name'][i])
    for el in df['alts']:
      for y in el:
        if y not in t and (y.find('Mega')==-1 and (gen=='xy' or gen=='sm')):
          t.append(y)
          a=df[df['name']==y].index.values[0]
          df=df.drop(a)
    for el in df['name']:
      if el=='Toxtricity-Low-Key' or el.find('Genesect-')!=-1:
        a=df[df['name']==el].index.values[0]
        df=df.drop(a)
    df.reset_index(drop=True)
    df.head()

    df[df['name']=='Diancie-Mega']

    df[df['name']=='Necrozma-Dawn-Wings']

    """Con este programa determinamos la generación de cada Pokémon. Esto será útil luego, ya que es una teoría que nosotros tenemos acerca de la relación entre los Pokémon, y su uso."""

    def flatten(xss):
        return [x for xs in xss for x in xs]

    def splitter(string):
      numbers=[int(num) for num in re.findall(r'\d+', string)]
      words=[wor for wor in re.findall(r'\D+', string)]
      return flatten([words,numbers])


    urllib3.disable_warnings()
    r=[]
    v=[]
    t=range(len(df['name']))
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/List_of_Pok%C3%A9mon_by_National_Pok%C3%A9dex_number'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      x=x.split('70px-')
      x=x[-1]
      if x.find('png')!=-1 and x.find('70px')==-1 and x.find('archives')==-1 and x.find('/')==-1 and x.find('HOME')==-1:
        x=x.replace(".png'",'')
        x=x.replace("_",' ')
        x=x.replace("%27","'")
        x=x.replace("%C3%A9","é")
        x=splitter(str(x))
        r.append(x)
    for el in r:
      if len(el)!=2 and len(el)<4:
        v.append([el[0]+str(el[-1]),el[1]])
      elif len(el)!=2 and len(el)>=3:
        v.append([el[0]+str(el[-1])+el[1],el[2]])
      else:
        v.append(el)
    print(v)
    dexdf=pd.DataFrame(v,columns=['name','Dex_Num'])
    df=pd.merge(df,dexdf,on='name',how='left')
    df.head()

    def gening(num):
      if num<=151: #Mew
        return 1
      elif num<=251: #Celebi
        return 2
      elif num<=386: #Deoxys
        return 3
      elif num<=493: #Arceus
        return 4
      elif num<=649: #Genesect
        return 5
      elif num<=721: #Volcanion
        return 6
      elif num<=807: #Zeraora, porque Meltan y Melmetal solo se jugaron en octava y novena
        return 7
      elif num<=898: #Calyrex, porque las formas de Hisui se jugaron en novena
        return 8
      elif num<=1025: #Pecharunt, el final de novena generación
        return 9
      else: #CAP
        return 0
    t=[]
    for el in df['Dex_Num']:
      t.append(gening(el))
    df['gen']=t
    df.head()

    """Esto es una función para un mapa de calor."""

    def correlation_heatmap(newdf):
        _ , ax = plt.subplots(figsize =(30, 30))
        colormap = sns.diverging_palette(220, 10, as_cmap = True)

        _ = sns.heatmap(
            newdf.corr(),
            cmap = colormap,
            square=True,
            cbar_kws={'shrink':.9 },
            ax=ax,
            annot=True,
            linewidths=0.1,vmax=1.0, linecolor='white',
            annot_kws={'fontsize':12 }
        )

        plt.title('Mapa de calor a partir de la correlación entre las variables', y=1.05, size=15)

    """##Movimientos

    Ahora que tenemos estos datos, hay que obtener los movimientos y para eso hay que repetir el proceso anterior pero con cada Pokémon.

    Los movimientos son una lista gigantesca, y a cada Pokémon le asignaremos un lista de movimientos determinada, sin embargo, lo que nos interesa de estos movimientos son una serie de datos que nos indica como actúan esos movimientos con los Pokémon, se lo añadiremos al DataFrame original (df).
    """

    urllib3.disable_warnings()
    r=[]
    v=[]
    http = urllib3.PoolManager()
    website = 'https://www.smogon.com/dex/'+gen+'/moves/'
    openwebsite = http.request('GET', website)
    links=openwebsite.data
    links=str(links)
    links=links.replace("\\'","'")
    links=links.split('"moves":')
    links=links[1]
    links=links.split('"types":')
    links=links[0]
    links=links[1:]
    links=links[:-2]
    links=links.split('},')
    for i in range(len(links)):
      if i<len(links)-1:
        links[i]=links[i]+'}'
      links[i]=json.loads(links[i],cls=LazyDecoder)
    movedf=pd.DataFrame.from_dict(links[0],orient='index')
    movedf=movedf.transpose()
    for i in range(len(links)-1):
      movedf2=pd.DataFrame.from_dict(links[i+1],orient='index')
      movedf2=movedf2.transpose()
      movedf=pd.concat([movedf,movedf2],ignore_index=True)
    movedf.head()

    urllib3.disable_warnings()
    r=[]
    v=[]
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/Additional_effect'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      if x.find('(move)')!=-1 and x.find('(move)>')==-1 and x.find('(move)<')==-1:
          r.append(x.rstrip(x[-1]).replace('_',' ').replace('/wiki/','').replace(' (move)',''))
      if x.find('<td>')!=-1 and x.find('%')!=-1:
          x=x.replace('<td>','').replace("'",'').replace('%','')
          x=float(x)
          r.append(x/100)
    for i in range(27):
      del r[0]
    b=[]
    k=0
    for x in movedf['name']:
      for i in range(len(r)):
        if x==r[i] and str(r[i+1])!=r[i+1]:
          b.append(r[i+1])
          k=1
          break
      if k==0:
        b.append(0)
      k=0
    movedf['Effect %']=b
    b=[]
    movedf.head()

    """En este código obtenemos las diferentes categorías que tiene cada movimiento, estas categorías son diversas y depende del tipo de movimiento. Así tenemos varias categorías que obtendremos a continuación en una lista."""


    urllib3.disable_warnings()
    r=[]
    v=[]
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/Category:Moves_by_effect'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      if x.find('/wiki/Category:')!=-1 and x.find('bulbapedia')==-1 and (x.find('by')==-1 or x.find('weight')!=-1):
        r.append('https://bulbapedia.bulbagarden.net'+x.rstrip(x[-1]))
        v.append(x.rstrip(x[-1]).replace('/wiki/Category:','').replace('_',' ').replace('%27',"'").replace('%C3%A9','é'))
    del r[-1]
    del v[-1]
    s=[]
    t=[]
    u=[]
    for x in r:
      http = urllib3.PoolManager()
      openwebsite = http.request('GET', x)
      links=openwebsite.data.split()
      s.append(links)
    for i in range(len(s)):
      for x in s[i]:
        x=str(x).replace('href','')
        x=x.replace('b\'','')
        x=x.replace('=','')
        x=x.replace('"','')
        x=x.replace('%27',"'")
        if x.find('(move)')!=-1 and x.find('(move)>')==-1 and x.find('(move)<')==-1:
          t.append(x.rstrip(x[-1]).replace('_',' ').replace('/wiki/','').replace(' (move)',''))
      u.append(t)
      t=[]
    w=[]
    k=0
    for i in range(len(u)):
      for x in movedf['name']:
        for j in range(len(u[i])):
          if x==u[i][j]:
            w.append(1)
            k=1
            break
        if k==0:
          w.append(0)
        k=0
      movedf[v[i]]=w
      w=[]
    movedf.head()

    urllib3.disable_warnings()
    r=[]
    v=[]
    move_type_list=[]
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/Category:Moves_by_effect'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      if x.find('/wiki/Category:')!=-1 and x.find('bulbapedia')==-1 and x.find('by')!=-1 and x.find('weight')==-1:
        r.append('https://bulbapedia.bulbagarden.net'+x.rstrip(x[-1]))
    del r[0]
    del r[0]
    print(r)
    s=[]
    t=[]
    u=[]
    for x in r:
      http = urllib3.PoolManager()
      openwebsite = http.request('GET', x)
      links=openwebsite.data.split()
      s.append(links)
    for i in range(len(s)):
      for x in s[i]:
        x=str(x).replace('href','')
        x=x.replace('b\'','')
        x=x.replace('=','')
        x=x.replace('"','')
        x=x.replace('%27',"'")
        if x.find('/wiki/Category:')!=-1 and x.find('bulbapedia')==-1 and x.find('by')==-1 and x.find('Category:Moves')==-1:
          t.append('https://bulbapedia.bulbagarden.net'+x.rstrip(x[-1]))
          v.append(x.rstrip(x[-1]).replace('/wiki/Category:','').replace('_',' ').replace('%27',"'").replace('%C3%A9','é'))
    print(t)
    move_type_list=v
    print(v)
    w=[]
    for x in t:
      http = urllib3.PoolManager()
      openwebsite = http.request('GET', x)
      links=openwebsite.data.split()
      w.append(links)
    y=[]
    z=[]
    for i in range(len(w)):
      for x in w[i]:
        x=str(x).replace('href','')
        x=x.replace('b\'','')
        x=x.replace('=','')
        x=x.replace('"','')
        x=x.replace('%27',"'")
        if x.find('(move)')!=-1 and x.find('(move)>')==-1 and x.find('(move)<')==-1:
          y.append(x.rstrip(x[-1]).replace('_',' ').replace('/wiki/','').replace(' (move)',''))
      z.append(y)
      y=[]
    b=[]
    for i in range(len(z)):
      for x in movedf['name']:
        for j in range(len(z[i])):
          if x==z[i][j]:
            b.append(1)
            k=1
            break
        if k==0:
          b.append(0)
        k=0
      movedf[v[i]]=b
      b=[]
    movedf.head()

    movedf[movedf['name']=='Recover']

    urllib3.disable_warnings()
    r=[]
    t=[]
    v=[]
    w=[]
    move_type_list=[]
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/Category:Moves_by_stat_modification'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      if x.find('/wiki/Category:')!=-1 and x.find('the')!=-1:
        t.append('https://bulbapedia.bulbagarden.net'+x.rstrip(x[-1]))
        v.append(x.rstrip(x[-1]).replace('/wiki/Category:','').replace('_',' ').replace('%27',"'").replace('%C3%A9','é'))
    print(t)
    print(len(v))
    for x in t:
      http = urllib3.PoolManager()
      openwebsite = http.request('GET', x)
      links=openwebsite.data.split()
      w.append(links)
    y=[]
    z=[]
    for i in range(len(w)):
      for x in w[i]:
        x=str(x).replace('href','')
        x=x.replace('b\'','')
        x=x.replace('=','')
        x=x.replace('"','')
        x=x.replace('%27',"'")
        if x.find('(move)')!=-1 and x.find('(move)>')==-1 and x.find('(move)<')==-1:
          y.append(x.rstrip(x[-1]).replace('_',' ').replace('/wiki/','').replace(' (move)',''))
      z.append(y)
      y=[]
    print(z)
    b=[]
    for i in range(len(z)):
      for x in movedf['name']:
        for j in range(len(z[i])):
          if x==z[i][j]:
            b.append(1)
            k=1
            break
        if k==0:
          b.append(0)
        k=0
      movedf[v[i]]=b
      b=[]
    movedf.head()

    movedf[movedf['name']=='Ominous Wind']

    """Antes de continuar, cambiamos el poder de algunos movimientos que pueden ser usados y que son importantes."""

    lista_moves=['Frustration','Return']
    lista_moves2=['Fishious Rend','Bolt Beak']
    for i in range(len(movedf['name'])):
      if str(movedf['name'][i]) in lista_moves:
        movedf.at[i,'power']=102
      elif str(movedf['name'][i]) in lista_moves2:
        movedf.at[i,'power']=170
    movedf[movedf['name']=='Bolt Beak']

    move_category=movedf.columns
    move_category=move_category.values.tolist()
    move_category=move_category[12:]
    print(move_category)

    """Nos quedamos con los standard"""

    movedf2=movedf[movedf['isNonstandard']=='Standard'].reset_index(drop=True)
    movedf2.head()

    """Ahora obtenemos los Pokémon que pueden aprender cada movimiento"""

    def string_adapt(string):
      string=string.replace("'",'')
      string=string.replace(' ','-')
      string=string.lower()
      return(string)

    """Primero obtenemos la lista de Pokémon por cada movimiento (es como aparece en Smogon)"""

    urllib3.disable_warnings()
    r=[]
    v=[]
    for x in movedf['name']:
      http = urllib3.PoolManager()
      website = 'https://www.smogon.com/dex/'+gen+'/moves/'+string_adapt(x)+'/'
      openwebsite = http.request('GET', website)
      links=openwebsite.data
      links=str(links)
      links=links.split('{"description":')[1]
      links=links.split('"pokemon":')[1]
      links=links.split('}]]')[0]
      r.append(links)
    movedf['learn_pokemon']=r
    movedf.head()

    """Después obtenemos la lista de movimientos que aprende cada Pokémon."""

    t=[]
    for i in range(len(df)):
      t.append([])
    for i in range(len(movedf)):
      for j in range(len(df)):
        if movedf.iloc[i]['learn_pokemon'].count(df.iloc[j]['name'])>0:
          t[j].append(movedf.iloc[i]['name'])
    df['moves_learn']=t
    df.head()

    """Finalmente calculamos cuantos movimientos de cada categoría tiene cada Pokémon."""


    c=[]
    for j in range(len(df['moves_learn'])):
      c=[movedf[movedf['name']==index] for index in df['moves_learn'][j]]
      for i in range(len(c)):
        c[i] = c[i].values.tolist()
        c[i] = [item for sublist in c[i] for item in sublist]
        c[i] = c[i][12:-1]
      res = list()
      for j in range(0, len(move_category)):
        tmp = 0
        for i in range(0, len(c)):
          tmp = tmp + c[i][j]
        res.append(tmp)
    df[move_category]=res
    df.head()

    """##Tipos

    Ahora daremos paso a los tipos
    """

    urllib3.disable_warnings()
    r=[]
    v=[]
    http = urllib3.PoolManager()
    website = 'https://www.smogon.com/dex/'+gen+'/pokemon'
    openwebsite = http.request('GET', website)
    links=openwebsite.data
    links=str(links)
    links=links.split('"types":[{')
    links=links[1]
    links='{'+links
    links=links.split('],"items":[{')
    links='['+links[0]+']'
    links=json.loads(links,cls=LazyDecoder)
    typesdf=pd.DataFrame.from_dict(links[0],orient='index')
    typesdf=typesdf.transpose()
    for i in range(len(links)-1):
      typesdf2=pd.DataFrame.from_dict(links[i+1],orient='index')
      typesdf2=typesdf2.transpose()
      typesdf=pd.concat([typesdf,typesdf2],ignore_index=True)
    typesdf.head()

    """Obtenemos la tabla de tipos"""

    type_chart=[]
    for i in range(len(typesdf)):
      type_chart.append([])
    for i in range(len(typesdf)):
      for j in range(len(typesdf)):
        type_chart[i].append(typesdf['atk_effectives'][i][j][1])
    print(type_chart)

    """Obtenemos las relaciones de cada tipo"""

    def_type_chart=[]
    for i in range(len(typesdf)):
      def_type_chart.append([])
    for i in range(len(typesdf)):
      for j in range(len(typesdf)):
        def_type_chart[i].append(typesdf['atk_effectives'][j][i][1])
    print(def_type_chart)

    offensive=[]
    defensive=[]
    for name in typesdf['name']:
      offensive.append('offensive_against_'+str(name))
      defensive.append('defensive_against_'+str(name))
    typesdf[offensive]=type_chart
    typesdf[defensive]=def_type_chart
    typesdf.head()

    """Obtenemos las relaciones de cada combinación de 2 tipos, sin contar las que sean tipo único."""

    def max_list(t,s):
      w=[]
      if len(t)!=len(s):
        return 'Error'
      else:
        for i in range(len(t)):
          w.append(max(t[i],s[i]))
      return w
    double_types=[]
    for i in range(len(typesdf)):
      for j in range(len(typesdf)):
        if i != j:
          double_types.append([typesdf['name'][i]]+[typesdf['name'][j]]+(typesdf[defensive].iloc[i]*typesdf[defensive].iloc[j]).tolist()+(max_list(typesdf[offensive].iloc[i].values.tolist(),typesdf[offensive].iloc[j].values.tolist())))
    double_typesdf=pd.DataFrame(double_types,columns=['type_1','type_2']+defensive+offensive)
    double_typesdf.head()

    """Añadimos a cada Pokémon los tipos que resiste, teniendo en cuenta las habilidades."""

    defensive_profile=[]
    for types in df['types']:
      if len(types)>1:
        defensive_profile.append(double_typesdf[(double_typesdf['type_1']==types[0]) & (double_typesdf['type_2']==types[1])][defensive].values.tolist()[0])
      else:
        defensive_profile.append(typesdf[(typesdf['name']==types[0])][defensive].values.tolist()[0])
    defensivedf=pd.DataFrame(defensive_profile,columns= defensive)
    for i in range(len(df['name'])):
      if 'Levitate' in df['abilities'][i]:
        defensivedf['defensive_against_Ground'][i]=0
      elif 'Water Absorb' in df['abilities'][i] or 'Storm Drain' in df['abilities'][i] or 'Dry Skin' in df['abilities'][i]:
        defensivedf['defensive_against_Water'][i]=0
      elif 'Lightning Rod' in df['abilities'][i] or 'Motor Drive' in df['abilities'][i]:
        defensivedf['defensive_against_Electric'][i]=0
      elif 'Sap Sipper' in df['abilities'][i]:
        defensivedf['defensive_against_Grass'][i]=0
      elif 'Flash Fire' in df['abilities'][i]:
        defensivedf['defensive_against_Fire'][i]=0
      elif 'Dry Skin' in df['abilities'][i] or 'Fluffy' in df['abilities'][i]:
        defensivedf['defensive_against_Fire'][i]=2*defensivedf['defensive_against_Fire'][i]
      elif 'Water Bubble' in df['abilities'][i] or 'Heatproof' in df['abilities'][i]:
        defensivedf['defensive_against_Fire'][i]=0.5*defensivedf['defensive_against_Fire'][i]
    df=pd.concat([df,defensivedf],axis=1)

    offensive_profile=[]
    for types in df['types']:
      if len(types)>1:
        offensive_profile.append(double_typesdf[(double_typesdf['type_1']==types[0]) & (double_typesdf['type_2']==types[1])][offensive].values.tolist()[0])
      else:
        offensive_profile.append(typesdf[(typesdf['name']==types[0])][offensive].values.tolist()[0])
    offensivedf=pd.DataFrame(offensive_profile,columns= offensive)
    df=pd.concat([df,offensivedf],axis=1)
    df.head()

    """Comprobamos que esté bien hecho."""

    df[df['name']=='Rotom']['defensive_against_Ground']

    """Añadimos un valor nuevo que estará determinado por la suma de la fuerza ofensiva de un tipo frente a su fuerza defensiva."""

    t=[]
    w=[]
    s=[]
    for i in range(len(df['name'])):
      t.append(sum(df[offensive].iloc[i].values.tolist())/sum(df[defensive].iloc[i].values.tolist()))
      s.append(sum(df[offensive].iloc[i].values.tolist()))
      w.append(sum(df[defensive].iloc[i].values.tolist()))
    df['type_value']=t
    df['offensive_type_value']=s
    df['defensive_type_value']=w
    type_value=['type_value','offensive_type_value','defensive_type_value']
    df.head()

    offensive_alpha=max(df['offensive_type_value'].values.tolist())
    defensive_alpha=max(df['defensive_type_value'].values.tolist())
    offensive_delta=[sum(type_chart[i]) for i in range(len(type_chart))]
    offensive_delta=[offensive_delta[i]/min(offensive_delta) for i in range(len(offensive_delta))]
    offensive_delta_matrix=[[offensive_delta[i]*offensive_delta[j] for i in range(len(offensive_delta))] for j in range(len(offensive_delta))]
    defensive_delta=[sum(def_type_chart[i]) for i in range(len(def_type_chart))]
    defensive_delta=[defensive_delta[i]/min(defensive_delta) for i in range(len(defensive_delta))]
    defensive_delta_matrix=[[defensive_delta[i]*defensive_delta[j] for i in range(len(defensive_delta))] for j in range(len(defensive_delta))]

    def type_coordinate(types_list):
      if len(types_list)==1:
        return [typesdf[typesdf['name']==types_list[0]].index[0],typesdf[typesdf['name']==types_list[0]].index[0]]
      else:
        return [typesdf[typesdf['name']==types_list[0]].index[0],typesdf[typesdf['name']==types_list[1]].index[0]]
    print(type_coordinate(df['types'][0]))

    offensive_total=[df['offensive_type_value'][i]/(offensive_alpha*defensive_delta_matrix[type_coordinate(df['types'][i])[0]][type_coordinate(df['types'][i])[1]]) for i in range(len(df['name']))]
    defensive_total=[df['defensive_type_value'][i]/(defensive_alpha*offensive_delta_matrix[type_coordinate(df['types'][i])[0]][type_coordinate(df['types'][i])[1]]) for i in range(len(df['name']))]
    average_total=[offensive_total[i]/defensive_total[i] for i in range(len(offensive_total))]

    df['offensive_total']=offensive_total
    df['defensive_total']=defensive_total
    df['average_total']=average_total
    df.head()

    """Ahora a cada Pokémon le damos un valor en función del coverage que tiene, es decir cuántos golpes superefectivos puede efectuar con sus movimientos."""

    def max_list(array_1,array_2):
      res=[]
      if len(array_1)!=len(array_2):
        return False
      else:
        for i in range(len(array_1)):
          res.append(max(array_1[i],array_2[i]))
      return res
    def power_multiplier(type_1,type_2, abilities):
      if type_1 in type_2 and 'Adaptability' in abilities:
        return 2
      elif type_1 in type_2:
        return 1.5
      else:
        return 1
    offensive_coverage=[]
    power=[]
    strongest_stab=[]
    avg_power_type=[]
    for name in typesdf['name']:
      offensive_coverage.append('offensive_coverage_against_'+name)
      power.append('max_power_'+name)
      avg_power_type.append('avg_power_'+name)
    coverage_options=[]
    max_power=[]
    avg_power=[]
    movepool_size=[]
    a=0
    b=0
    c=0
    d=0
    e=0
    banned_moves=flatten([movedf[movedf['Moves that require recharging']==1]['name'].values.tolist(),movedf[movedf['Moves that cause the user to faint']==1]['name'].values.tolist()])
    print(banned_moves)
    for i in range(len(df)):
      coverage_options.append([])
      max_power.append([0 for typing in typesdf['name']])
      avg_power.append([0 for typing in typesdf['name']])
      strongest_stab.append(0)
      e=df['types'][i]
      movepool_size.append(len(df['moves_learn']))

      for move in df['moves_learn'][i]:
        count=len(df['moves_learn'][i])
        acc=movedf[movedf['name']==move]['accuracy']
        atk=df['atk'][i]
        spa=df['spa'][i]
        if move not in banned_moves:
          if 'Pixilate' in df['abilities'][i] and (movedf[movedf['name']==move]['type'].values.tolist())[0]=='Normal':
            a='Fairy'
          elif 'Aerilate' in df['abilities'][i] and (movedf[movedf['name']==move]['type'].values.tolist())[0]=='Normal':
            a='Flying'
          elif 'Galvanize' in df['abilities'][i] and (movedf[movedf['name']==move]['type'].values.tolist())[0]=='Normal':
            a='Flying'
          elif 'Liquid Voice' in df['abilities'][i] and any(movedf[movedf['name']==move]['Sound-based moves'].values==1):
            a='Water'
          else:
            a=movedf[movedf['name']==move]['type'].values[0]
          if 'Strong Jaw' in df['abilities'][i] and any(movedf[movedf['name']==move]['Biting moves']==1):
            b=(movedf[movedf['name']==move]['power'].values[0])*1.5
          elif 'Iron Fist' in df['abilities'][i] and any(movedf[movedf['name']==move]['Punching moves']==1):
            b=(movedf[movedf['name']==move]['power'].values[0])*1.2
          elif ('Pixilate' in df['abilities'][i] or 'Aerilate' in df['abilities'][i] or 'Galvanize' in df['abilities'][i]) and (movedf[movedf['name']==move]['type'].values.tolist())[0]=='Normal':
            b=(movedf[movedf['name']==move]['power'].values[0])*1.2
          elif 'Punk Rock' in df['abilities'][i] and any(movedf[movedf['name']==move]['Sound-based moves']==1):
            b=(movedf[movedf['name']==move]['power'].values[0])*1.3
          elif 'Water Bubble' in df['abilities'][i] and any(movedf[movedf['name']==move]['type']=='Water'):
            b=(movedf[movedf['name']==move]['power'].values[0])*2
          else:
            b=movedf[movedf['name']==move]['power'].values[0]
          c=typesdf['name'].values.tolist().index(a)
          d=movedf[movedf['name']==move]['category'].values[0]
          if not (a in coverage_options[-1]) and b>0 and d=='Physical' and (atk>=spa or atk>=100) and any(acc>=80):
            coverage_options[-1].append(a)
            max_power[-1][c]=max(b*power_multiplier(a,e,df['abilities'][i])*df['atk'][i],max_power[-1][c])
            if b>=65:
              avg_power[-1][c]=b*power_multiplier(a,e,df['abilities'][i])*df['atk'][i]/count+avg_power[-1][c]
          if not (a in coverage_options[-1]) and b>0 and d=='Special' and (atk<=spa or spa>=100) and any(acc>=80):
            coverage_options[-1].append(a)
            max_power[-1][c]=max(b*power_multiplier(a,e,df['abilities'][i])*df['spa'][i],max_power[-1][c])
            if b>=65:
              avg_power[-1][c]=b*power_multiplier(a,e,df['abilities'][i])*df['spa'][i]/count+avg_power[-1][c]
          if a in e and b>0 and d=='Physical' and atk>=spa and any(acc>=80):
            if 'Adaptability' in df['abilities'][i]:
              strongest_stab[-1]=max(b*2*df['atk'][i],strongest_stab[-1])
            else:
              strongest_stab[-1]=max(b*1.5*df['atk'][i],strongest_stab[-1])
          if a in e and b>0 and d=='Special' and atk<=spa and any(acc>=80):
            if 'Adaptability' in df['abilities'][i]:
              strongest_stab[-1]=max(b*2*df['spa'][i],strongest_stab[-1])
            else:
              strongest_stab[-1]=max(b*1.5*df['spa'][i],strongest_stab[-1])
    df['strongest_stab']=strongest_stab
    df['movepool_size']=movepool_size
    df[power]=max_power
    df[avg_power_type]=avg_power
    b=[]
    a=[0 for x in typesdf['name']]
    for array in coverage_options:
      for typing in coverage_options[0]:
        a=max_list(typesdf.iloc[list(np.where(typesdf['name']==typing))[0][0]][offensive].values.tolist(),a)
      b.append(a)
      a=[0 for x in typesdf['name']]
    df[offensive_coverage]=b
    df.head()

    df[['name']+ power].head()

    """##Habilidades

    La siguiente parte son las habilidades, otro conjunto de datos que merece la pena estudiar.
    """

    urllib3.disable_warnings()
    r=[]
    v=[]
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/Ability'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      x=x.replace("'",'')
      if x.find('(Ability)')!=-1 and x.find('(Ability)>')==-1:
        r.append(x.replace('/wiki/','').replace('_',' ').replace(' (Ability)',''))
    r = list(dict.fromkeys(r))
    abilitiesdf= pd.DataFrame(r,columns=['Name'])
    t=[]
    http = urllib3.PoolManager()
    website = 'https://bulbapedia.bulbagarden.net/wiki/Category:Abilities_by_effect'
    openwebsite = http.request('GET', website)
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      x=x.replace('%27',"'")
      if x.find('/wiki/Category:')!=-1 and x.find('bulbapedia')==-1 and x.find('by_effect')==-1:
        t.append('https://bulbapedia.bulbagarden.net'+x.rstrip(x[-1]))
        v.append(x.rstrip(x[-1]).replace('/wiki/Category:','').replace('_',' ').replace('%C3%A9',"é"))
    del t[-1]
    del v[-1]
    s=[]
    w=[]
    y=[]
    for x in t:
      http = urllib3.PoolManager()
      openwebsite = http.request('GET', x)
      links=openwebsite.data.split()
      s.append(links)
    for i in range(len(s)):
      for x in s[i]:
        x=str(x).replace('href','')
        x=x.replace('b\'','')
        x=x.replace('=','')
        x=x.replace('"','')
        x=x.replace('%27',"'")
        if x.find('(Ability)')!=-1 and x.find('(Ability)>')==-1 and x.find('(Ability)<')==-1:
          w.append(x.replace('_',' ').replace('/wiki/','').replace(' (Ability)','').replace("'",''))
      y.append(w)
      w=[]
    b=[]
    for i in range(len(y)):
      for x in abilitiesdf['Name']:
        for j in range(len(y[i])):
          if x==y[i][j]:
            b.append(1)
            k=1
            break
        if k==0:
          b.append(0)
        k=0
      abilitiesdf[v[i]]=b
      b=[]
    abilitiesdf.head()

    """Aquí tenemos una lista con todas las categorías de habilidades."""

    ability_category=abilitiesdf.columns
    ability_category=ability_category.values.tolist()
    ability_category=ability_category[1:]
    print(ability_category)

    t=[]
    a=0
    for s in range(abilitiesdf.shape[1]-1):
      for x in df['abilities']:
        for r in range(len(abilitiesdf['Name'])):
          for ab in x:
            if abilitiesdf['Name'].iloc[r]==ab:
              a=max(a,abilitiesdf.iloc[r,s+1])
            if a==1:
              break
        t.append(a)
        a=0
      df[ability_category[s]]=t
      t=[]
    df.head()

    """Definimos lo que es una mala habilidad, que es algo que algunos Pokémon poseen y los hace peor."""

    def intersection(lst1, lst2):
        lst3 = [value for value in lst1 if value in lst2]
        return lst3
    weather_set = ['Drought', 'Drizzle', 'Snow Warning', 'Sand Stream', 'Sand Spit', 'Orichalcum Pulse','Desolate Land','Primordial Sea']
    weather_disrupt = ['Cloud Nine', 'Air Lock', 'Delta Stream']
    t=[]
    t2=[]
    for el in df['abilities']:
      if intersection(weather_set,el)!=[]:
        t.append(1)
      else:
        t.append(0)
      if intersection(weather_disrupt,el)!=[]:
        t2.append(1)
      else:
        t2.append(0)
    df['Abilities that set up Weather conditions'] = t
    df['Abilities that negate Weather conditions'] = t2
    df[df['Abilities that set up Weather conditions'] == 1][['name','abilities']]

    df[df['name']=='Torkoal']['Abilities that set up Weather conditions']

    df=df[df['isNonstandard']=='Standard'].reset_index(drop=True)
    df.head()

    """#Parte 2: Formalización de datos

    Una vez terminada la obtención de datos, es necesario alterar algunos de estos datos para que sean útiles.

    El tier es un factor importante, por eso vamos a formalizar todas las BanList en el tier superior.
    """

    df.loc[df.formats == 'OUBL','formats'] = 'Uber'
    df.loc[df.formats == 'UUBL','formats'] = 'OU'
    df.loc[df.formats == 'RUBL','formats'] = 'UU'
    df.loc[df.formats == 'NUBL','formats'] = 'RU'
    df.loc[df.formats == 'PUBL','formats'] = 'NU'
    df.loc[df.formats == 'ZUBL','formats'] = 'PU'
    tiers = ['Uber', 'OU', 'UU', 'RU', 'NU', 'PU','ZU']
    df = df[df['formats'].isin(tiers)].reset_index(drop=True)
    df.head()

    """Enseñamos cuantos Pokémon están en cada tier."""

    tier_mapping = {tier:num for num, tier in enumerate(tiers)}
    df['tier_num'] = df.apply(lambda x: tier_mapping[x.formats], axis=1)
    tier_mapping

    """Ahora veremos los Pokémon que no encajan en su tier según sus stats, y veremos las anomalías presentes. Para ello hay que calcular la media y la desviación típica de cada tier en el que está el Pokémon y ver qué Pokémon caen 2 desviaciones típicas por encima o debajo de este valor.

    Contamos cuantos movimientos aparecen en movepools de Pokémon y lo dividimos por tiers.
    """

    movedf['uber count'] = 0
    movedf['ou count'] = 0
    movedf['uu count'] = 0
    movedf['ru count'] = 0
    movedf['nu count'] = 0
    movedf['pu count'] = 0
    movedf['zu count'] = 0

    for i in range(len(df['name'])):
      for move in df['moves_learn'][i]:
        for j in range(len(movedf['name'])):
          if move==movedf['name'][j]:
            movedf.at[j, df['formats'][i].lower() + ' count'] += 1

    movedf['count'] = movedf['uber count'] + movedf['ou count'] + movedf['uu count'] + movedf['ru count'] + movedf['nu count'] + movedf['pu count']+movedf['zu count']
    movedf = movedf.reset_index(drop=True)
    movedf.head()

    plt.figure(figsize=(20, 6))
    movedf['count'].hist(bins=50, color=sns.color_palette('muted')[0])
    plt.gca().set(title='Frequencies of Moves by the Number of Pokemon that Learn Them')

    print(movedf.iloc[movedf.nlargest(10, 'count').index]['name'].values.tolist())
    print(movedf.iloc[movedf.nsmallest(10, 'count').index]['name'].values.tolist())

    num_plots = 10
    fig, ax = plt.subplots(1,num_plots, figsize=(25,10))

    heatmap_df = movedf.sort_values('count', ascending=False)[[t.lower() + ' count' for t in tiers]]
    num_elem = len(heatmap_df)
    split_heat_df = []

    for i in range(0, num_elem, int(num_elem/num_plots)):
        split_heat_df.append(heatmap_df.iloc[i:i+int(num_elem/num_plots)])

    for hdf, axis, i in zip(split_heat_df, ax, range(0, num_elem, int(num_elem/num_plots))):
        sns.heatmap(data=heatmap_df.iloc[i:i+int(num_elem/num_plots)],
                    annot=False, cmap='Blues', ax = axis, cbar=False)
        axis.get_yaxis().set_visible(False)
        axis.set(title="{} to {}".format(i, i+int(num_elem/num_plots)-1))

    fig.suptitle('Percent of Pokemon that Learn each Move by Tier')

    """Esto lo utilizamos para ver cuantos movimientos exclusivos aprende cada Pokémon."""

    exclusive_moves = set(movedf[movedf['count'] <= 3].index)
    df['num_exclusive'] = df.apply(lambda x: len(exclusive_moves.intersection(x['moves_learn'])), axis=1)
    df.head()

    """Ahora trabajaremos un poco con stats. En primer lugar, no todos los Pokémon tienen el mismo poder. A simple vista, con los stats, es fácil ver que algunos destacan sobre otros en ese departamento, incluso dentro del mismo tier, pero normalmente no vemos toda la imagen. Ahora mostramos los Pokémon con stats muy extraños dentro del tier."""

    bstdf = df[['formats', 'bst']].groupby('formats').agg([np.mean, np.std])
    bstdf.columns = ['bst_mean', 'bst_std']
    df2 = df.reset_index().merge(bstdf, left_on='formats', right_on='formats')

    under = df2[(df2['bst'] < df2['bst_mean'] - 2*df2['bst_std']) & (df2['formats'] != 'ZU')]
    over = df2[(df2['bst'] > df2['bst_mean'] + 2*df2['bst_std']) & (df2['formats'] != 'Uber')]

    under[['formats', 'name', 'types', 'abilities', 'hp', 'atk', 'def', 'spa', 'spd', 'spe', 'bst', 'bst_mean','bst_std']]

    """Muchos de los Pokémon que aparecen tienen la particularidad de que sus stats no reflejan su uso ni su verdadero potencial. Por ejemplo, Pikachu se usa con el orbe eléctrico que le multiplica por 2 los stats ofensivos, Clefairy usa Mineral Evolutivo y Azumarill y Diggersby tienen potencia, una habilidad que les duplica el ataque físico, por lo que sería lógico (ya que la máquina no entiende estos cambios) cambiar los stats de acuerdo a la fórmula."""

    over[['formats', 'name', 'types', 'abilities', 'hp', 'atk', 'def', 'spa', 'spd', 'spe', 'bst', 'bst_mean','bst_std']]

    """Aquí vemos a los contrarios, Regigigas, Virizion y Diancie, que tienen problemas con sus stats, Regigigas tiene el detrimento de su habilidad, que lo tendremos en cuenta, pero Virizion y Diancie simplemente tienen mala distribución ofensiva-defensiva. (Mucho porcentaje de sus stats son inútiles)

    ### Formula de stats
    ![image.png](data:image/png;base64,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)

    Como se puede ver en esta fórmula, los stats tienen la siguiente formula, entonces lo que vamos a hacer es dar una función que nos dé la base inicial y el cambio y nos de la base final.
    """

    def formula_cambio_base(x,a):
      return round((a*(99 + 2*x) - 99)/2)
    formula_cambio_base(60,2)

    """Con esta fórmula podemos ir rectificando los errores a la alza y a la baja. Para ello vamos a contabilizar todos los cambios."""

    for i in range(len(df['name'])):
      el=df['name'][i]
      if el.find('Pikachu')!=-1:
        df['atk'][i]=formula_cambio_base(df['atk'][i],2)
        df['spa'][i]=formula_cambio_base(df['spa'][i],2)
      elif el.find('Wishiwashi')!=-1:
        df.loc[df['name']=='Wishiwashi',['hp','atk','def','spa','spd','spe']]=[45,140,130,140,135,30]
      elif el.find('Regigigas')!=-1:
        df['atk'][i]=formula_cambio_base(df['atk'][i],1/2)
        df['spe'][i]=formula_cambio_base(df['spe'][i],1/2)
    for i in range(len(df['abilities'])):
      el=df['abilities'][i]
      if 'Huge Power' in el or 'Pure Power' in el:
        df['atk'][i]=formula_cambio_base(df['atk'][i],2)
      elif 'Gorilla Tactics' in el:
        df['atk'][i]=formula_cambio_base(df['atk'][i],1.5)
      elif el==['Truant']:
        df['atk'][i]=formula_cambio_base(df['atk'][i],0.5)
      elif el==['Slow Start']:
        df['atk'][i]=formula_cambio_base(df['atk'][i],0.5)
        df['spe'][i]=formula_cambio_base(df['spe'][i],0.5)
      elif el==['Defeatist']:
        df['atk'][i]=formula_cambio_base(df['atk'][i],0.5)
        df['spa'][i]=formula_cambio_base(df['spa'][i],0.5)
    for i in range(len(df['Eviolite'])):
      if df['Eviolite'][i]==1 and df['name'][i].find('Pikachu')==-1:
        df['def'][i]=formula_cambio_base(df['def'][i],1.5)
        df['spd'][i]=formula_cambio_base(df['spd'][i],1.5)
    df['bst']=[sum(df[['hp','atk','def','spa','spd','spe']].values.tolist()[i]) for i in range(len(df))]
    df['offensive_prowess']=[max(df[['atk','spa']].values.tolist()[i])/df['bst'].values.tolist()[i] for i in range(len(df))]
    df['defensive_prowess']=[sum(df[['hp','def','spd']].values.tolist()[i])/df['bst'].values.tolist()[i] for i in range(len(df))]
    df['averageness']=[max(df[['hp','atk','def','spa','spd','spe']].values.tolist()[i])/df['bst'].values.tolist()[i]-1/6 for i in range(len(df))]
    df.head()

    bstdf = df[['formats', 'bst']].groupby('formats').agg([np.mean, np.std])
    bstdf.columns = ['bst_mean', 'bst_std']
    df2 = df.reset_index().merge(bstdf, left_on='formats', right_on='formats')

    under = df2[(df2['bst'] < df2['bst_mean'] - 2*df2['bst_std']) & (df2['formats'] != 'ZU')]
    over = df2[(df2['bst'] > df2['bst_mean'] + 2*df2['bst_std']) & (df2['formats'] != 'Uber')]

    under[['formats', 'name', 'types', 'abilities', 'hp', 'atk', 'def', 'spa', 'spd', 'spe', 'bst', 'bst_mean','bst_std']]

    over[['formats', 'name', 'types', 'abilities', 'hp', 'atk', 'def', 'spa', 'spd', 'spe', 'bst', 'bst_mean','bst_std']]

    df[df['name']=='Azumarill']

    """Antes de continuar es necesario añadir un último valor para 'tier_num' basado en el valor medio del uso.

    Para ello utilizaremos obtendremos el uso medio de cada Pokémon de OU con los datos de Smogon.
    """


    t=[]
    gen_num={'rb':1,'gs':2,'rs':3,'dp':4,'bw':5,'xy':6,'sm':7,'ss':8,'sv':9}
    tiering=['zu','pu','nu','ru','uu','ou','ubers']
    tiering_num={'ZU':'zu','PU':'pu','NU':'nu','RU':'ru','UU':'uu','OU':'ou','Uber':'ubers'}
    z=[]
    for el in df['name']:
      z.append(0.0)
    do=[]
    mi=[]
    tabla_maximos={}

    urllib3.disable_warnings()
    http = urllib3.PoolManager()
    website = 'https://www.smogon.com/stats'
    openwebsite = http.request('GET', website)
    links=openwebsite.data
    links=str(links)
    links=links.replace('href','')
    links=links.replace("b\'",'')
    links=links.replace('<html>','')
    links=openwebsite.data.split()
    for x in links:
      x=str(x).replace('href','')
      x=x.replace('b\'','')
      x=x.replace('=','')
      x=x.replace('"','')
      x=x.replace("'",'')
      if x.find('</a>')!=-1 and x.find('-')!=-1:
        t.insert(-1,website+'/'+x[:7])
    for tier in tiering:
      v=[]
      for el in t:
        openwebsite = http.request('GET', str(el))
        links=openwebsite.data
        links=str(links)
        links=links.replace('href','')
        links=links.replace("b\'",'')
        links=links.replace('<html>','')
        links=openwebsite.data.split()
        for x in links:
          x=str(x).replace('href','')
          x=x.replace('b\'','')
          x=x.replace('=','')
          x=x.replace('"','')
          x=x.replace("'",'')
          if x.find('gen' + str(gen_num[gen]) + tier + '-1500')!=-1:
            v.insert(0,el + '/' + 'gen' + str(gen_num[gen]) + tier + '-1500.txt')
      W=[df['name'].values.tolist()]
      w=[0 for el in df['name']]
      for el in v:
        datoszu=urllib.request.urlopen(el)
        soupzu=BeautifulSoup(datoszu)
        zu = str(soupzu)
        zu=zu.replace(' ','')
        zu=zu.replace('%','')
        if zu.find('Totalbattles:0')==-1 and zu.find('Totalbattles:1')==-1: #Asegurandonos que hay batallas
          table=zu.split('|')
          del table[:9]
          del table[-1]
          table[:] = (value for value in table if value != '\n')
          g=[]
          s=int(len(table)/7)
          for i in range(s):
            g.append([table[7*i+1],float(table[7*i+2])])
          for i in range(len(df['name'])):
            for j in range(len(g)):
              if g[j][0]==df['name'][i]:
                w[i]=float(g[j][1])
              elif g[j][0]+'-Mega'==df['name'][i] and (gen=='xy' or gen=='sm') and tiering_num[df['formats'][i]]==tier and tiering_num[df['formats'][i]]!=tiering_num[df[df['name']==g[j][0]]['formats'].values.tolist()[0]]:
                w[i]=float(g[j][1])
          W.append(w)
          w=[0 for el in df['name']]
      te=['name']
      #num es una variable que definimos para que cada vez que pase el mes se actualice la posición
      for i in range(len(W)-1):
        te.append('Uso {}'.format(i+1))
      W=list(map(list, zip(*W)))
      usodf=pd.DataFrame(W,columns=te)
      usodf['Uso Medio']=usodf[usodf[te[1:]] >0.0].mean(1).fillna(0)
      for i in range(len(df['name'])):
        for j in range(len(usodf['name'])):
          if df['name'][i]==usodf['name'][j] and tiering_num[df['formats'][i]]==tier:
            z[i]=usodf['Uso Medio'][j]/100
            mi.append(usodf['Uso Medio'][j]/100)
      if mi!=[]:
        tabla_maximos[tier]=max(mi)
      else:
        tabla_maximos[tier]=1.0
      mi=[]
    print(tabla_maximos)
    df['avg_use']=z
    df.head()

    usodf[usodf['name']=='Necrozma-Dusk-Mane']

    df[df['name']=='Marowak']['formats']

    len(df['avg_use'])

    """Ahora definimos el nuevo tier_num"""

    df[np.isnan(df['tier_num'])]

    lista_unica=df['tier_num'].values.tolist()
    t=df['tier_num'].values.tolist()
    s=df['avg_use'].values.tolist()
    for i in range(len(t)):
      tier=tiering_num[df['formats'][i]]
      s[i]=(1-0.000001)*(tabla_maximos[tier]-s[i])/tabla_maximos[tier]+t[i]
    df['tier_num_complete']=s
    print(df[['tier_num','tier_num_complete']])

    df['tier_num_complete'] = pd.Series(s, index=df.index)  # Create a Series with the appropriate index

    df['tier_num_complete'] = df['tier_num_complete'].fillna(6.999999)
    df = df.fillna(0.0)
    print(df[np.isnan(df['tier_num_complete'])])

    """Ahora obtenemos todos los posibles datos que pueden ayudarnos a obtener el tier de cada Pokémon. Y utilizamos clasificadores para ver cómo de buenos son nuestros resultados."""


    stats = ['hp', 'atk', 'def', 'spa', 'spd', 'spe','offensive_prowess','defensive_prowess','averageness'] #bst excluded
    move_category=flatten([move_category,['strongest_stab','movepool_size']])
    types=['offensive_total','defensive_total','average_total']
    particularities=['num_exclusive']
    abilities=['Abilities that set up Weather conditions','Abilities that negate Weather conditions']
    df_y = df.loc[:, 'tier_num_complete']
    df_y_abs = df.loc[:, 'tier_num']
    df_x = df.loc[:, stats + move_category + ability_category + power + offensive_coverage + defensive + type_value + types + avg_power_type + particularities + abilities]
    scaler=StandardScaler()
    df_x=scaler.fit_transform(df_x)
    df_x=pd.DataFrame(df_x,columns=stats + move_category + ability_category + power + offensive_coverage + defensive + type_value + types + avg_power_type + particularities + abilities)
    print(df_x.head())
    print(df_y.head())


    def easy_dual_plot(x, y1, y2, figsize=(12, 4), title='', xlabel='', ylabel1='', ylabel2=''):
        fig, ax = plt.subplots(figsize=figsize) #2, 1,
        ax.set(title=title)
        ax.plot(x, y1, color='b')
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel1, color='b')
        ax.tick_params('y', colors='b')

        ax2 = ax.twinx()
        ax2.plot(x, y2, color='r')
        ax2.set_ylabel(ylabel2, color='Red')
        ax2.tick_params('y', colors='r')

    max_depth_range = list(range(1, 10))
    train_errors, cv_errors = [],[]

    for d in max_depth_range:
        final_model = ens.GradientBoostingRegressor(loss='huber', max_depth = d)
        final_model.fit(df_x, df_y)
        train_errors.append(np.mean(np.sqrt(mean_squared_error(df_y, final_model.predict(df_x)))))
        cv_errors.append(np.mean(np.sqrt(-cross_val_score(final_model, df_x, df_y, cv=10, scoring='neg_mean_squared_error'))))

    easy_dual_plot(max_depth_range, cv_errors, train_errors, title='Training and CV Error vs Max Depth',
                  xlabel='Max Depth', ylabel1='CV RMSE', ylabel2='Training RMSE')

    importances = final_model.feature_importances_
    indices = np.argsort(importances)[::-1]
    attributes = list(df_x.columns)
    df_final[gen]=importances
    if gen==gens[0]:
      df_final.index=attributes
    # Print the feature ranking
    print("Feature ranking:")

    for f in range(10):
        print("{}. feature {} ({})".format(f + 1, df_x.columns[indices[f]], importances[indices[f]]))

    df['prediction'] = final_model.predict(df_x)
    t=[]
    for el in df['prediction']:
      t.append(math.floor(el))
    df['rounded_prediction'] = t
    df['residuals'] = abs(df['tier_num_complete'] - df['prediction'])
    df['residuals exact'] = abs(df['tier_num'] - df['rounded_prediction'])
    df2=df.loc[abs(df['tier_num_complete'] - df['prediction'])>0.5]
    a=len(df2)
    df3=df.loc[(df['tier_num'] != df['rounded_prediction'])]
    b=len(df3)
    df4=df.loc[(df['tier_num'] != df['rounded_prediction']) & (df['tier_num_complete'] - df['prediction'])>0.5]
    c=len(df4)
    print([a,b,c])
    print(df2[['name','formats', 'tier_num', 'tier_num_complete', 'prediction', 'rounded_prediction', 'residuals', 'residuals exact']].sort_values('residuals',ascending=False).head())
    print(df3[['name','formats', 'tier_num', 'tier_num_complete', 'prediction', 'rounded_prediction', 'residuals', 'residuals exact']].sort_values('residuals exact',ascending=False).head())

    print(df3[['name','formats', 'tier_num', 'tier_num_complete', 'prediction', 'rounded_prediction', 'residuals', 'residuals exact']])

    results = df_y.to_frame()
    results['Fitted Values'] = final_model.predict(df_x)
    results['Modified Fitted Values'] = results['Fitted Values']
    results['Residuals'] = np.floor(df_y.values) - np.floor(final_model.predict(df_x))
    fig, ax = plt.subplots(figsize=(10, 3))
    ax.set(title='Distribution of Residuals', ylabel='Count', xlabel='Residuals')
    results['Residuals'].hist(ax=ax, bins=10)

print(df_final.sort_values(by=gens[0],ascending=False))
